#!/usr/bin/env python

desc = """

Oldboy - https://www.youtube.com/watch?v=eRBwvIX7Sao

Fight to remove stale Audience Stream profiles.

"""

from pymongo import MongoClient
from pymongo import read_preferences
from pymongo.errors import PyMongoError
from bson.objectid import ObjectId
import logging
from logging.handlers import SysLogHandler
from splunk_handler import SplunkHandler
from time import sleep
import arrow
import re
import random
import sys
import traceback
import argparse
import daemon
import threading


def whoami():
   from socket import gethostbyname
   from socket import getfqdn
   try:
      fqdn = getfqdn()
   except Exception as e:
      logging.warning("can't get my FQDN: %s" % e)
   try:
      ip = ""
      if fqdn:
	 ip = gethostbyname(fqdn)
   except Exception as e:
      logging.warning("can't get my IP: %s" % e)
   if fqdn and ip:
      whoami = "%s (%s)" % (fqdn, ip)
   elif fqdn:
      whoami = fqdn
   elif ip:
      whoami = ip
   else:
      whoami = None
      logging.warning("I don't know who I am!")
   return whoami


class MyLogFilter(logging.Filter):
   def __init__(self, *allowed):
      self.allowed = [logging.Filter(name) for name in allowed]

   def filter(self, record):
      return any(f.filter(record) for f in self.allowed)


class OldboyError(Exception):
   pass


class OldboyStats():

   import arrow

   def __init__(self):
      self.startTime = arrow.utcnow()
      self.counter = 0

   def get(self):
      return self.counter

   def put(self, value):
      self.counter = self.counter + value

   def reset(self):
      self.counter = 0

   def durationInSecs(self):
      return (arrow.utcnow() - self.startTime).seconds

   def ratePerHour(self):
      return ((float(self.counter) / self.durationInSecs()) * 3600)

   def ratePerMin(self):
      return (float(self.counter) / self.durationInSecs() * 60)

   def ratePerSec(self):
      return (float(self.counter) / self.durationInSecs())


class TimeRange():

   zones = dict();

   # huzzah for hard coding
   zones[11000000] = "US/Pacific"
   zones[21000000] = "US/Eastern"
   zones[31000000] = "Europe/Dublin"
   zones[71000000] = "Europe/Berlin"

   def __init__(self, range=None):
      self.startHour = None
      self.startMin = None
      self.stopHour = None
      self.stopMin = None

      if range:
	 rangeRegex = re.compile('(\d\d):(\d\d)-(\d\d):(\d\d)')
	 rangeMatch = rangeRegex.match(range)
	 self.startHour = int(rangeMatch.group(1))
	 self.startMin = int(rangeMatch.group(2))
	 self.stopHour = int(rangeMatch.group(3))
	 self.stopMin = int(rangeMatch.group(4))


class Purge(threading.Thread):

   def __init__(self, args):

      for k in args:
	 setattr(self, k, args[k])

      if not self.when:
	 self.when='always'

      if not self.test:

	 self.db = self.dbConn[self.dbName]

	 self.profileStats = OldboyStats()

	 if self.throttle < 5:
	    self.throttle = 5

	 try:
	    splunk_handler = SplunkHandler(
	       host=self.splunkHost,
	       port=self.splunkPort,
	       username='datacloud_purge',
	       password='Purge4Tealium',
	       index='datacloud_purge',
	       hostname=whoami(),
	       verify=False
	    )

	    self.splunk = logging.getLogger('splunk')
	    self.splunk.setLevel(logging.INFO)
	    self.splunk.addHandler(splunk_handler)

	 except Exception as e:
	    logging.warning("Failed to configure splunk handler: %s" % e)
	    logging.warning("splunk logging defaulting to root logger")
	    self.splunk = logging.getLogger('root')
	    pass

	 super(Purge, self).__init__(target=self.run)


   def time_to_run(self):

      if not self.timeRange:
	 return True

      utc = arrow.utcnow()
      zone = self.timeRange.zones[self.shardTokenPrefix]
      now = utc.to(zone)
      start = now.replace(hour=self.timeRange.startHour,minute=self.timeRange.startMin,second=0,microsecond=0)
      stop = now.replace(hour=self.timeRange.stopHour,minute=self.timeRange.stopMin,second=0,microsecond=0)
      if stop < start and now.hour >= 12:
	 stop = stop.replace(hours=24)
      if stop < start and now.hour < 12:
	 start = start.replace(hours=-24)

      weekend = False
      if not self.strict:
	 dow = now.weekday()
	 weekend = (dow == 5) or (dow == 6)

      logging.debug("current %s time is %s" % (zone, now))
      logging.debug("should run between %s and %s" % (start, stop))

      return (now >= start and now < stop or weekend)


   def run(self):

      self.splunk.info("timestamp=%s, status=started, throttle=%d, when=%s, "
		       "purged_visitor_profiles=0, purged_visitor_profiles_per_sec=0"
		       % (arrow.utcnow().isoformat(), self.throttle, self.when))

      while (True):

	 if self.time_to_run():
	    self.profileStats.reset()
	    # self.visitStats.reset()
	    logging.info("purging")

            self.purge() 

	    # logging.info("purged %d profiles (%.02f/s) and %d visits (%.02f/s)"
	    # 	         % (self.profileStats.get(), self.profileStats.ratePerSec(),
	    #		    self.visitStats.get(), self.visitStats.ratePerSec()))

	    logging.info("purged %d profiles (%.02f/s)"
		         % (self.profileStats.get(), self.profileStats.ratePerSec()))

	    # self.splunk.info("timestamp=%s, status=active, batch_size=%d, throttle=%d, when=%s, "
	    # 	             "purged_visitor_profiles=%d, purged_visitor_profiles_per_sec=%.02f, "
	    # 	             "purged_visitor_visits=%d, purged_visitor_visits_per_sec=%.02f"
	    # 		     % (arrow.utcnow().isoformat(), self.batchSize, self.throttle, self.when, self.profileStats.get(),
	    # 			self.profileStats.ratePerSec(), self.visitStats.get(), self.visitStats.ratePerSec()))

	    self.splunk.info("timestamp=%s, status=active, throttle=%d, when=%s, "
		             "purged_visitor_profiles=%d, purged_visitor_profiles_per_sec=%.02f"
			     % (arrow.utcnow().isoformat(), self.throttle, self.when, self.profileStats.get(),
				self.profileStats.ratePerSec()))

	 else:

	    # self.splunk.info("timestamp=%s, status=inactive, batch_size=%d, throttle=%d, when=%s, "
	    # 	             "purged_visitor_profiles=0, purged_visitor_profiles_per_sec=0, "
	    #               "purged_visitor_visits=0, purged_visitor_visits_per_sec=0"
	    # 		     % (arrow.utcnow().isoformat(), self.batchSize, self.throttle, self.when))

	    self.splunk.info("timestamp=%s, status=inactive, throttle=%d, when=%s, "
		             "purged_visitor_profiles=0, purged_visitor_profiles_per_sec=0"
			     % (arrow.utcnow().isoformat(), self.throttle, self.when))

	 sleep(self.throttle)


   def purge(self):

      random.seed()
      start = random.randint(self.shardTokenPrefix, self.shardTokenPrefix + self.maxPart + 1 - self.partRange)
      end = start + self.partRange

      logging.debug("purging token range %d to %s" % (start, end))

      now = arrow.utcnow().naive

      # temporarily restrict deletes to profiles that expired over 6 months ago
      #now = now.replace(months=-6).naive

      try:

       for target in self.db.visitor_profiles.find( { "shard_token" : { "$gte" : start, "$lte" : end },
 						      "expire_at" : { "$lt" : now },
						      "$or" : [ {"replaced_by" : { "$exists" : 0 } },
							        {"replaced_by" : ""} ] },
						    { "_id" : 1, "shard_token" : 1, "replaces" : 1 }
 			 ).hint("shard_token_1_expire_at_1_replaced_by_1").limit(self.batchSize):
 
	  if "replaces" in target:
	     v_result = self.db.visitor_profiles.delete_many( { "_id" : { "$in" : target["replaces"] } })
	     p_result = self.db.visitor_profiles.delete_many( { "shard_token" : target["shard_token"], "_id" : target["_id"] })
	     self.profileStats.put(v_result.deleted_count + p_result.deleted_count)
	  else:
	     p_result = self.db.visitor_profiles.delete_many( { "shard_token" : target["shard_token"], "_id" : target["_id"] })
	     self.profileStats.put(p_result.deleted_count)

      except PyMongoError as e:
	  logging.warning("%s" % e)
	  pass


def positive_integer(i):
   try:
      i = int(i)
      if i < 1: raise ValueError
   except ValueError:
      raise argparse.ArgumentTypeError("argument must be a "
                                       "positive integer")
   return i


def parse_args():

   gargle = argparse.ArgumentParser(prog = "oldboy", description=desc,
	       usage='%(prog)s [options] <value>',
	       formatter_class = argparse.RawDescriptionHelpFormatter)

   gargle.add_argument('--host', dest='dbHost', metavar="<mongodb_host>",
		      help='MongoDB server hostname or IP (default: localhost)',
		      default='localhost')

   gargle.add_argument('--port', dest='dbPort', metavar="<mongodb_port>",
		      type=positive_integer,
		      help='MongoDB server port (default: 27017)',
		      default=27017)

   gargle.add_argument('--db', dest='dbName', metavar="<database name>",
	 help='Database containing visitor_profiles. (default: datacloud)',
	 default='datacloud')

   gargle.add_argument('--when', dest='when', metavar="<start_time-stop_time>",
	 help='Daily time window for when purging is allowed.  Specified in 24hr clock format as hh:mm-hh:mm. (default: Always)')

   gargle.add_argument('--strict', action='store_true',
	 help='Apply time window to weekends too.  Otherwise, purge constantly during local weekends. (default: False)')

   gargle.add_argument('--test', action='store_true',
	 help='Only checks to see if purging would be active for given time window. (default: False)')

   gargle.add_argument('--throttle', dest='throttle', metavar="<seconds>",
		      type=positive_integer,
		      help='Seconds to pause between purge batches (minimum 5). (default: 5)',
		      default=5)

   gargle.add_argument('--batch', dest='batchSize', metavar="<int>",
 		      type=positive_integer,
 		      help='Size of purge batches. (default: 500)',
 		      default=500)

   gargle.add_argument('--threads', dest='threads', metavar="<int>",
 		      type=positive_integer,
 		      help='Number of concurrent purge threads. (default: 4)',
 		      default=4)

   gargle.add_argument('--partition-range', dest='partRange', metavar="<int>",
		      type=positive_integer,
		      help='Size of randomized partition ranges for purge queries. (default: 10)',
		      default=10)

   gargle.add_argument('--max-partition', dest='maxPart', metavar="<int>",
		      type=positive_integer,
		      help='Maximum datacloud partition number. (default: 99)',
		      default=99)

   gargle.add_argument('--splunkHost', dest='splunkHost', metavar="<host>",
		      help='Splunk indexer host. (default: 10.221.1.17)',
		      default='10.221.1.17')

   gargle.add_argument('--splunkPort', dest='splunkPort', metavar="<port>",
		      type=positive_integer,
		      help='Splunk indexer port. (default: 8089)',
		      default=8089)

   gargle.add_argument('--verbose', action='store_true',
		      help='log to stderr in addition to syslog (default: False)')

   gargle.add_argument('--debug', action='store_true',
		      help='log debugging info to stderr (default: False)')

   gargle.add_argument('shardTokenPrefix', metavar="<int>",
		      type=positive_integer,
		      help='Shard token region prefix for this purge job.')

   return gargle.parse_args()


def test(args):

   if args.when:
      timeRange = TimeRange(args.when)
      logging.debug("start hour = %d, start min = %d, stop hour = %d, stop min = %d" % (timeRange.startHour,
										    timeRange.startMin,
										    timeRange.stopHour,
										    timeRange.stopMin))
   else:
      timeRange = None
   args.timeRange = timeRange

   purge = Purge(vars(args))
   if purge.time_to_run():
      print "active"
   else:
      print "inactive"


def main():

   args = parse_args()

   if args.verbose:
      logLevel = logging.DEBUG
   else:
      logLevel = logging.INFO

   logging.root.name = 'oldboy'
   logging.root.setLevel(logLevel)

   formatter = logging.Formatter('%(name)s: %(levelname)s: %(message)s')

   if args.debug or args.test:
      stderr = logging.StreamHandler()
      stderr.setFormatter(formatter)
      stderr.setLevel(logging.DEBUG)
      logging.root.addHandler(stderr)
      keepOpen = stderr.stream.fileno()
   else:
      syslog = SysLogHandler(address='/dev/log')
      syslog.setFormatter(formatter)
      syslog.setLevel(logLevel)
      syslog.addFilter(MyLogFilter('oldboy'))
      logging.root.addHandler(syslog)
      keepOpen = syslog.socket.fileno()

   if (args.test):
      test(args)
      sys.exit(0)

   urglefloggah = daemon.DaemonContext()
   urglefloggah.detach_process = False
   urglefloggah.files_preserve = [keepOpen]

   if args.debug:
      urglefloggah.stderr = stderr.stream
      
   try:
      with urglefloggah:

	 if args.when:
	    timeRange = TimeRange(args.when)
	    logging.debug("start hour = %d, start min = %d, stop hour = %d, stop min = %d" % (timeRange.startHour,
	                                                                                  timeRange.startMin,
	                                                                                  timeRange.stopHour,
	                                                                                  timeRange.stopMin))
	 else:
	    timeRange = None
	 args.timeRange = timeRange

         if not args.test:
	    args.dbConn = MongoClient(args.dbHost, args.dbPort, read_preference=read_preferences.SecondaryPreferred())

         for t in xrange(args.threads):
	    purge = Purge(vars(args))
	    purge.start()

	 sys.exit(0)

   except Exception as e:
      logging.critical("Terminating with uncaught exception: %s" % e)
      traceback.print_exc(file=sys.stderr)
      raise SystemExit(1)


if __name__ == '__main__': main()

